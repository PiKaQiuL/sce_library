---
--- Generated by EmmyLua(https://github.com/EmmyLua)
--- Created by xindong.
--- DateTime: 2021/10/11 14:43
---

local platform              = require 'base.platform'
local local_version         = require 'update.core.local_version'
local lua_state_name = __lua_state_name
local co                    = require 'base.co'
local create_request        = require 'base.request'
local request               = create_request('updater')
local env                   = require 'update.core.env'
local argv                  = require 'base.argv'
local map_path              = require 'update.core.map_path'

--local update            = require 'update.init'
local confirm           = require 'base.confirm'
local path              = require 'base.path'
local account           = require 'base.account'
local reload            = require 'reload'
local json              = require 'json'
--local update            = require 'update.init'
local DefaultProgressBind   = require 'base.progress'.DefaultProgressBind
local replace_url_list = require 'update.core.replace_update_url'
local util = require 'base.util'
local split = util.split
local path_last_part = util.path_last_part
local path_parent = util.path_parent
local math_floor = math.floor
local math_ceil  = math.ceil
local math_random = math.random
local max = math.max
local min = math.min
local try = try
local table_insert = table.insert
local setmetatable = setmetatable
local coroutine_async = coroutine.async
local type = type
local tostring = tostring
local root_path            = path(io.get_root_dir())
local io_add_resource_path = io.add_resource_path
local io_remove            = io.remove
local io_rename            = io.rename
local io_write             = io.write

local do_unzip = co.wrap(io.unzip_file)  
local do_unzip_from_mem = nil -- 从内存里解压一定是多线程多以初始值为空
if type(io.unzip_file_from_mem) == "function" then -- 如果存在从内存解压就一定存在多线程解压
    do_unzip_from_mem = co.wrap(io.unzip_file_from_mem)
end

local io_serialize = io.serialize
local io_exist_dir = io.exist_dir
local io_exist_file = io.exist_file
local io_create_dir = io.create_dir
local io_copy_to_folder = io.copy_to_folder
local io_attribute_type = io.attribute_type
local io_read = io.read
local io_copy = io.copy
local io_copy_not_decode = io.copy_not_decode
local base_json_decode = base.json.decode
local io_file_size = io.file_size or function() return 0, 0 end  -- 做一下兼容...等二进制发出去后去掉or后面的
local io_list = io.list
local common_stat_sender = common.stat_sender
local error = error
local fmt = fmt
local assert = assert
local sleep = coroutine.sleep
local sleep_one_frame = coroutine.sleep_one_frame
local get_file_md5 = common.get_file_md5
local ipairs = ipairs
local pairs = pairs
local math_sqrt = math.sqrt


local current_platform = common.get_platform()

local max_thread_count = 64
if current_platform == "Windows" then
    max_thread_count = 30  -- Windows上面的select最多只能支持64个fd, 所以保险起见30吧. linux一般最大fd是1024
end


local api_pak_version_manager = require 'update.core.local_api_pak_version'
local map_pak_version_manager = require 'update.core.local_map_pak_version'
local update_recode = require 'update.core.update_record'

local old_assert = _G.assert
_G.assert = function(e, s)
    if not e then
        if debug_bp then
            debug_bp(true)
        end
        return old_assert(e, s)
    end
    return e, s
end
---@class PatchInfo
---@field url string
---@field md5 string
---@field size number

-- { name: string; version: number; packet_type: number; url?: string; md5?: string, size?: number; is_server?: boolean, suffix?: string, status?: string};
---@class update_info_row
---@field name string
---@field version number
---@field packet_type number
---@field path string
---@field url string
---@field md5 string
---@field size number
---@field is_server boolean
---@field suffix string
---@field patch_info PatchInfo|nil
---@field alias string
---@field true_url string
---@field original_size number

---@class map_update_request
---@field name string
---@field part number|nil   -- 正常的请求
---@field value number|nil  -- special请求, 比如{name = "$package_type", value = 3}

---@class get_update_download_info_param
---@field update_list (map_update_request|string)[]  这是要查看的地图的数组
---@field default_part number   1: CLIENT, 2: SERVER, 3: EDITOR, default: 1   (目前来讲3是CLIENT+SERVER的意思)
---@field suffix string|nil  可以选择填 "mob" 或 "client" , 也可以填nil, 代表使用global_client_suffix
---@field reason string  -- 为什么请求更新


---@class UpdateSubTask
---@field info update_info_row
---@field patch_failed boolean  如果打patch失败了, 那就标记为true
---@field zip_path string   要解压的压缩包的路径
---@field max_downloaded number  该SubTask已经下载的最大数值
---@field download_file_to_mem boolean
local UpdaterSubTask = {}
UpdaterSubTask.__index = UpdaterSubTask
function UpdaterSubTask:__tostring()
    return fmt('%s(%s)', self.info.name, self:suffix())
end

function UpdaterSubTask:suffix()
    if self.info.is_server then
        return 'server'
    else
        return self.info.suffix or 'client'
    end
end

---@class MultiThreadDownloadPolicy
---@field policy_id number
---@field low_speed number  单位: KB
---@field low_speed_time number  单位: 秒
---@field thread_count number  并发数

---@class UpdateTask
---@field request DoUpdateParams
---@field to_download_deque event_deque  event_deque<UpdateSubTask>
---@field to_unzip_deque event_deque  event_deque<UpdateSubTask>
---@field status 'waiting'|'pending'|'aborted'|'success'|'cancelled'
---@field download_thread_finish_promise_list promise[]
---@field unzip_thread_finish_promise_list promise[]
---@field all_count number
---@field finished_count number
---@field running_http_hub table
---@field finish_promise promise
---@field used_memory number  已经使用的内存
---@field save_file_buffer table 下载到内存里的文件
---
--- 运行时赋值的数据
---@field thread_count number
---@field remain_thread_count number
---@field policy MultiThreadDownloadPolicy
local UpdateTask = class 'UpdateTask'
---@param request DoUpdateParams
function UpdateTask:ctor(request)
    self.request = request  ---@type DoUpdateParams
    self.startup = request.startup
    self.update_folder_root = path(io.get_root_dir()) / 'Update' / _G.update_subpath
    self.cache_folder_path = self.update_folder_root / 'cache/maps'
    self.cache_server_folder_path = self.update_folder_root / 'cache_server/maps'

    self.to_download_deque = base.event_deque()
    self.to_unzip_deque = base.event_deque()
    self.download_thread_finish_promise_list = {}
    self.unzip_thread_finish_promise_list = {}
    self.finished_count = 0
    self.finished_size = 0.0
    self.status = 'waiting'
    self.finish_promise = base.promise()

    self.all_count = 0
    self.all_size = 0.0
    self.downloaded_count = 0.0
    self.total_download_size = 0
    self.to_download_list = nil  ---@type update_info_row[]
    self.to_extract_bytes = 0
    self.extracted_bytes = 0
    self.running_http_hub = {} -- 存正在运行的http请求,和它当前的slow_speed_policy
end

---@param status string
function UpdateTask:set_status(status)
    self.status = status
    if status == 'aborted' then
        if debug_bp then
            debug_bp(true)
        end
    end
    log.info(('update task[%s] set status[%s]'):format(self, status))
    if self.request.status_callback then
        self.request.status_callback(status)
    end
end

function UpdateTask:_set_finish_promise_result()
    if self.status == 'success' then
        self.finish_promise:try_set_result()
    else
        self.finish_promise:try_set_result(to_exception(fmt('update task failed. status[%s]', self.status)))
    end
end

function UpdateTask:abort()
    self:set_status('aborted')
    self.to_unzip_deque:close()
    self.to_download_deque:close()
    for http in pairs(self.running_http_hub) do
        http:close()
    end
    self:_set_finish_promise_result()
end

function UpdateTask:cancel()
    self:set_status('cancelled')
    self.to_unzip_deque:close()
    self.to_download_deque:close()
    self.finish_promise:try_set_result()
    for http in pairs(self.running_http_hub) do
        http:close()
    end
    self:_set_finish_promise_result()
end


function UpdateTask:check_md5(full_path, md5, from_url, sub_task)
    if common.get_file_md5 then
        local downloaded_md5
        if sub_task.download_file_to_mem then
            downloaded_md5 = common.get_md5_from_http_stream(self.save_file_buffer[full_path])
        else
            downloaded_md5 = common.get_file_md5(full_path, true)
        end
        if downloaded_md5 ~= md5 then
            if argv.has('md5_failed_debug') then
                local base_path = root_path / 'md5_failed' / tostring(downloaded_md5)
                if not io_exist_dir(base_path) then
                    io_create_dir(base_path)
                    io_copy_not_decode(full_path, tostring(base_path / 'file.7z'))
                    io_write(tostring(base_path / 'info.json'), json.encode(sub_task))
                end
            end
            log.warn(('check md5 failed. full_path[%s], from_url[%s], downloaded_md5[%s] online_md5[%s]'):format(full_path, from_url, downloaded_md5, md5))
            return false
        end
    end

    return true
end

--去掉扩展名
local function delete_ext(str)
    local idx = str:match(".+()%.%w+$")
    if(idx) then
        return str:sub(1, idx-1)
    else
        return str
    end
end

--获取扩展名
local function getextension(filename)
    return filename:match(".+%.(%w+)$")
end
--这里只用到了old_path和patch_dir，因为直接在原本的文件夹里操作
function UpdateTask:apply_patch(old_path, patch_dir)
    if updater.request_apply_patch_multi_thread then
        local do_patch = co.wrap(updater.request_apply_patch_multi_thread)
        local result   = do_patch(old_path, patch_dir, old_path)
        log.info(("多线程打补丁结果 result[%s] old_path[%s] patch_dir[%s]"):format(result, old_path, patch_dir))
        return result
    end
    --[[
        读patch包中的文件修改信息，patch_info.json
    拿到一个对象数组，数组中每个对象描述一条文件的修改信息
    包含两个字段，path表示文件夹下的相对路径，state表示修改状态
    state为patch时，表示文件被修改，需要应用补丁
    state为same时，表示未被修改，不操作
    state为dir时，表示新版本存在一个文件夹，需要检查旧版是否存在，不存在则创建
    state为copy时，表示新版本新增一个文件，从patch_dir下对应位置复制过去
    state为delete_dir时，表示新版本删除了此文件夹
    state为delete_file时，表示新版本删除了此文件
    ]]--
    local res, content = io_read(patch_dir.."/$patch_info$.json");
    log.info("读取补丁信息:"..patch_dir.."/$patch_info$.json");
    log.info("结果码:"..res)
    if res == 0 then
        local table = base_json_decode(content)
        for i in pairs(table) do
            local use_old_md5_count = true
            if table[i].version and table[i].version == 2 then --第二版本的补丁
                use_old_md5_count = false
            end
            local target_path = old_path.."/"..table[i].path;--要操作的旧版文件路径
            local patchfile_path = patch_dir.."/"..table[i].path;  --补丁包内对应文件路径
            if table[i].md5_old then
                local now_md5 = get_file_md5(target_path, use_old_md5_count)  -- true代表不解混淆直接算md5
                local md5_old = table[i].md5_old
                if (md5_old ~= now_md5) then
                    log.info(("旧版文件[%s]md5校验失败，有外部改动. 记录的md5[%s], 当前md5[%s]"):format(target_path, md5_old, now_md5))
                    return 9
                end
            end
            if table[i].state == "patch" then --需要应用补丁
                patchfile_path = patchfile_path..".patch"; --补丁文件加.patch后缀
                local apply_patch_suc;
                if table[i].version and table[i].version == 2 then --第二版本的补丁
                    apply_patch_suc = updater.request_apply_patch_version2(target_path, patchfile_path, target_path)
                else
                    apply_patch_suc = updater.request_apply_patch(target_path, patchfile_path, target_path);
                end
                if apply_patch_suc then
                    local target_md5
                    if io_exist_file(target_path) then
                        target_md5 = get_file_md5(target_path, use_old_md5_count)
                    else
                        target_md5 = '不存在文件' .. target_path
                    end
                    if (target_md5 == table[i].md5_new) or (table[i].md5_new == nil) then
                        log.info("应用补丁成功:"..patchfile_path.."--->"..target_path)
                    else
                        log.info("应用补丁失败, md5不正确:"..patchfile_path.."--->"..target_path)
                        log.info("应用补丁后md5:"..target_md5)
                        log.info("补丁md5:"..get_file_md5(patchfile_path, use_old_md5_count))
                        return 7
                    end
                else
                    log.info("应用补丁失败:"..patchfile_path.."--->"..target_path)
                    return 1
                end
            elseif table[i].state == "dir" then --创建文件夹
                if io_create_dir(target_path) then
                    log.info("创建文件夹成功:"..target_path)
                else
                    log.info("创建文件夹失败:"..target_path)
                    return 2
                end
            elseif table[i].state == "copy" then --新文件，复制过去
                local res
                if io_copy_not_decode then
                    res = io_copy_not_decode(patchfile_path, target_path)
                else
                    res = io_copy(patchfile_path, target_path)
                end
                if res then
                    local target_md5 = get_file_md5(target_path, use_old_md5_count)
                    if (target_md5 == table[i].md5_new) or (table[i].md5_new == nil) then
                        log.info("复制文件成功:"..patchfile_path.."--->"..target_path)
                    else
                        log.info("复制文件失败, md5不正确:"..patchfile_path.."--->"..target_path)
                        log.info("错误文件md5:"..target_md5)
                        return 8
                    end
                else
                    log.info("复制文件失败:"..patchfile_path.."--->"..target_path)
                    return 3
                end
            elseif table[i].state == "delete_dir" then --要删除的文件夹
                if io_exist_dir(target_path) then
                    if io_remove(target_path) == 0 then
                        log.info("删除文件夹成功:"..target_path)
                    else
                        log.info("删除文件夹失败:"..target_path)
                        return 4
                    end
                end
            elseif table[i].state == "delete_file" then --要删除的文件
                if io_exist_file(target_path) then
                    if io_remove(target_path) == 0 then
                        log.info("删除文件成功:"..target_path)
                    else
                        log.info("删除文件失败:"..target_path)
                        return 5
                    end
                end
            end
        end
        return 0 --应用补丁成功了，返回0
    else
        log.info("读取补丁信息失败:"..patch_dir.."/$patch_info$.json")
        return 6
    end
end

---@param sub_task UpdateSubTask
---@param patch_path string
function UpdateTask:merge_patch(sub_task, patch_path, old_path, extract_path)
    assert(not sub_task.info.is_server)
    local package_name = sub_task.info.name

    local local_package_version = local_version:get(package_name)
    log.info(("merge_patch begin. package[%s], old_version[%s], online_version[%s]"):format(package_name, local_package_version, sub_task.info.version))

    -- 为了防止打补丁中途程序退出，设置local_version为0，并保存到VERSION.JSON 非多API的包打补丁才需要置0
    local_version:save_patch_cache(sub_task.info)
    

    log.info(('old[%s] + patch[%s] -> new[%s]'):format(sub_task.info.patch_info.src, patch_path, sub_task.info.patch_info.dest))
    local _, filesize
    if not sub_task.download_file_to_mem then
        _, filesize = io_file_size(patch_path)
    else
        filesize = self.save_file_buffer[patch_path]:get_size()
    end
    log.info("补丁包大小:" .. filesize)
    --新版补丁目录直接解压
    local target_path = delete_ext(patch_path)
    log.info("解压补丁包: " .. patch_path .. "->" .. target_path)

    --多线程解压
    local has_add_extracted = 0
    local result = -1
    if not sub_task.download_file_to_mem then                                                --文件流
        result = do_unzip(patch_path, target_path, function(total, progress, path)
            self.extracted_bytes = self.extracted_bytes + (progress - has_add_extracted)     -- 修正总共提取的字节数
            has_add_extracted = progress
            self.update_progress()
        end)
    else
        if self.save_file_buffer[patch_path] then
            result = do_unzip_from_mem(self.save_file_buffer[patch_path], target_path, function(total, progress, path)
                self.extracted_bytes = self.extracted_bytes + (progress - has_add_extracted)     -- 修正总共提取的字节数
                has_add_extracted = progress
                self.update_progress()
            end)
        else
            log.info("找不到解压文件 和 http流")
        end
    end

    self.extracted_bytes = self.extracted_bytes + (sub_task.info.patch_info.size - has_add_extracted)
    
    -- 提取结束后 增加量 一定是初始大小
    if self.save_file_buffer[patch_path] then --补丁解压结束
        self.save_file_buffer[patch_path]:clear()
        self.save_file_buffer[patch_path] = nil
        local zip_orgin_size = sub_task.info.original_size or sub_task.info.size --使用原大小
        self.used_memory = self.used_memory - zip_orgin_size -- 补丁解压结束 释放下载到内存的文件流
        self.download_used_mem = self.download_used_mem - zip_orgin_size
        log.info(("从内存解压结束还原下载内存 [%d]MB [%d]KB"):format(self:get_last_memory()))
        log.info(("下载已经使用的内存 [%d]MB [%d]KB"):format(self:format_memory(self.download_used_mem)))
    end
    self.update_progress()
    local patch_dir = delete_ext(patch_path)     --解压后的路径，同名文件夹
    if result ~= 0 then
        log.info("补丁包解压失败: " .. patch_path .. "->" .. target_path)
        return nil
    end
    io_remove(patch_path)
    local res, dir_list = io_list(patch_dir, 3)
    if res == 0 then
        log.info("补丁内文件")
        for i in pairs(dir_list) do
            log.info(dir_list[i])
        end
    end
    --old_path和extract_path都在res/maps下，patch_dir在cache里，是解压好的补丁包
    local res = self:apply_patch(old_path, patch_dir)
    if res ~= 0 then
        self.extracted_bytes = self.extracted_bytes - sub_task.info.patch_info.size     -- 补丁失败后清除解压补丁的进度
        self.update_progress()
        log.info(('错误码: %d, 打补丁失败, %s, %s, %s'):format(res, old_path, extract_path, patch_dir))
        common_stat_sender('patch_error', {
            guest_id = account.get_guest_id(),
            type = tostring(res),
            old_version = old_path,
            new_version = extract_path,
            patch_path = patch_dir
        })
        io_remove(patch_dir)     --解压后的补丁包
        return nil
    else
        self.extracted_bytes = self.extracted_bytes +
        ((sub_task.info.original_size or sub_task.info.size) - sub_task.info.patch_info.size)                                                   --补丁成功后修正提取的字节
        self.update_progress()
        log.info(('打补丁成功, %s, %s, %s'):format(old_path, extract_path, patch_dir))
        local_version:remove_patch_cache(sub_task.info)
        io_remove(patch_dir)

        -- 微信需要把新 zip 保存到本地
        --if platform.is_wx() or platform.is_qq() then
        --    ce.wx.call('fs_saveToLocal', new_version)
        --end

        return extract_path
    end

end

function UpdateTask:calc_download_filename(sub_task, download_info)
    local dot_split_result = split(download_info.url, '.')
    local part_split_result = split(download_info.url, '/')
    local ext = dot_split_result[#dot_split_result]
    local main_name = part_split_result[#part_split_result]
    if ext == 'patch' or ext == 'pat' then
        main_name = part_split_result[#part_split_result - 1] .. '-' .. main_name -- 下载的pat包 里面会有新旧版本号区分补丁内容 
    else
        main_name = tostring(sub_task.info.version) .. '-' .. main_name -- 直接下载的包 加个版本号的前缀
    end


    local full_path_parent = self.update_folder_root / (sub_task.info.is_server and 'cache_server' or 'cache') / 'maps' / sub_task.info.name
    local full_path = tostring(self.update_folder_root / (sub_task.info.is_server and 'cache_server' or 'cache') / 'maps' / sub_task.info.name / main_name)

    return full_path, full_path_parent
end

local policy_list = {
    --{0, 0, weight=10},
    {speed=50, time=15, weight=10},
    {speed=50, time=30, weight=10},
    {speed=30, time=15, weight=10},
    {speed=30, time=30, weight=10},
    {speed=11, time=15, weight=10},
    {speed=11, time=30, weight=10},
    {speed=2,  time=15, weight=10},
    {speed=2,  time=30, weight=10},
    { -- 拍脑袋想的策略 
        high_traffic = { speed = 8, time = 16 },-- 下载线程数 大于20 时
        mid_traffic = { speed = 32, time = 16 },-- 下载线程数 大于10 时
        low_traffic = { speed = 64, time = 16 },-- 下载线程数 小于10 时
    }
}

local thread_list = {
    8, max_thread_count / 4, max_thread_count,
}

local function calc_low_speed_policy()
    local guest_id = account.get_guest_id()
    local hash_code = common.string_hash(guest_id)
    local policy_id = hash_code % #policy_list + 1
    policy_id = 9
    local policy = policy_list[policy_id]
    local thread_count = thread_list[hash_code % #thread_list + 1]
    log.info(fmt('low_speed_policy: policy_id[%s] policy: [%sKB, %ss] thread_count[%s]', policy_id, policy.speed, policy.time, thread_count))
    return {
        policy_id = policy_id,
        thread_count = thread_count,
        low_traffic = policy.low_traffic,
        mid_traffic = policy.mid_traffic,
        high_traffic = policy.high_traffic,
    }
end

-- 根据运行的下载数 返回最慢下载策略
function UpdateTask:get_current_low_speed_policy()
    local slow_speed_abort_option = self.policy.low_traffic
    if self.used_http_request > 20 then
        slow_speed_abort_option = self.policy.high_traffic
    elseif self.used_http_request > 10 then
        slow_speed_abort_option = self.policy.mid_traffic
    end
    log.info("当前http请求数", self.used_http_request, "策略", json.encode(slow_speed_abort_option))
    if self.used_http_request < 0 then
        log.error("错误http请求数小于0", self.used_http_request)
    end
    return slow_speed_abort_option
end

-- 重设正在运行的 http请求的最低下载速度
function UpdateTask:set_running_request_low_speed_policy()
    local slow_speed_abort_option = self:get_current_low_speed_policy()
    for running_http, policy in pairs(self.running_http_hub) do
        if running_http.set_slow_speed_abort_option ~= nil then
            local running_http_count = math_ceil(self.used_http_request / 10) * 10
            if running_http_count < 10 then
                running_http_count = 10
            end
            local single_thread_speed = math_floor(self.max_download_speed / running_http_count / 10)
            single_thread_speed = max(single_thread_speed, slow_speed_abort_option.speed * 1024)
            local duration_time = slow_speed_abort_option.time
            if single_thread_speed > 200 * 1024 then --大于200K的速度时 把时间调大
                duration_time = 32
            end
            if single_thread_speed > 512 * 1024 then
                single_thread_speed = 512 * 1024 -- 单线程最大 512 K
            end
            running_http:set_slow_speed_abort_option(single_thread_speed,
                math_floor(duration_time * (math_random(8000, 12000) / 10000.0)))
        end
    end
end

--- 请求下载http,下载到文件,不分块,不然会超内存
function UpdateTask:request_http_download_zip_to_file(url, zip_size, sub_task, full_path, downloaded_bytes)
    if self.used_http_request >= self.max_http_request then
        log.info(("http请求过多,等一等 url[%s]"):format(url));
        sleep(1000)
    end
    self.used_http_request = self.used_http_request + 1
    local slow_speed_abort_option = self:get_current_low_speed_policy()
    self:set_running_request_low_speed_policy()
    local http = sce.httplib.create()
    self.running_http_hub[http] = slow_speed_abort_option
    local code, status = co.call(http.request, http, {
        url = url,
        method = 'GET',
        output = full_path,
        header = {
            -- 我们假设每个version的地图只要上了OSS就不会有改变了, 所以只用Range, 不用If-Range
            Range = downloaded_bytes > 0 and fmt('bytes=%s-', downloaded_bytes) or nil
        },
        --max_recv_speed = 1024*2000,
        progress = function(total, now)
            --log.info(fmt("progress: %s", now))
            self:_try_set_max_download(sub_task, now + downloaded_bytes)
        end,
        slow_speed_abort_option = {
            speed = slow_speed_abort_option.speed * 1024,
            time = math_floor(slow_speed_abort_option.time * (math_random(8000, 12000) / 10000.0)),
        }
    })
    self.used_http_request = self.used_http_request - 1
    self.running_http_hub[http] = nil
    self:set_running_request_low_speed_policy()
    return code, status
end

-- 下载一个单独的块 下载失败 自动重下 失败5次 返回下载失败 对于没分块的文件 下载失败一次 就失败了
function UpdateTask:request_http_download_zip_block(url, sub_task, download_range, end_pos, output_stream, retry_time)
    local code, status
    if self.used_http_request >= self.max_http_request then
        log.info(("http请求过多,等一等 url[%s] pos[%d]"):format(url, end_pos));
        sleep(1000)
    end
    self.used_http_request = self.used_http_request + 1
    local failed_count = 0
    while failed_count < retry_time do
        local slow_speed_abort_option = self:get_current_low_speed_policy()
        self:set_running_request_low_speed_policy()
        local http = sce.httplib.create()
        self.running_http_hub[http] = slow_speed_abort_option
        code, status = co.call(http.request, http, {
            url = url,
            method = 'GET',
            output = output_stream,
            header = {
                -- 我们假设每个version的地图只要上了OSS就不会有改变了, 所以只用Range, 不用If-Range
                Range = download_range
            },
            --max_recv_speed = 1024*2000,
            progress = function(total, now)
                --log.info(fmt("progress: %s", now))
                self:_try_set_max_download(sub_task, now, end_pos)
            end,
            slow_speed_abort_option = {
                speed = slow_speed_abort_option.speed * 1024,
                time = math_floor(slow_speed_abort_option.time * (math_random(8000, 12000) / 10000.0)),
            }
        })
        self.running_http_hub[http] = nil
        if code == 0 and (status == 200 or status == 206) then --参数里填了Range status就会是206
            break
        end
        
        output_stream:clear()
        failed_count = failed_count + 1
        log.info(("分块下载失败 失败次数%d 结尾%d subtask[%s]"):format(failed_count, end_pos, json.encode(sub_task)))
        if retry_time > 1 then -- 大于1代表分块下载失败 单独发一个
            common.stat_sender('download_abort', {
                url = url,
                downloaded = sub_task.max_downloaded,
                reason = 6, -- 分块下载失败
                code = code,
                policy_id = self.policy.policy_id,
                thread_count = self.policy.thread_count,
                retry_times_on_timeout = failed_count,
                platform = current_platform,
            })
        end
    end
    self.used_http_request = self.used_http_request - 1
    self:set_running_request_low_speed_policy()
    return code, status
end

-- 请求下载http 下载到内存 分块下载 
function UpdateTask:request_http_download_zip_to_mem(url, zip_size, sub_task, full_path, downloaded_bytes)
    local once_download_size = 16 * 1024 * 1024
    local last_download_size = zip_size
    local start_pos = 0
    local down_load_finish_promise_list = {}
    local output_stream_list = {}
    local retry_time = 5
    while last_download_size > 0 do
        local output_stream = sce.httplib.create_stream()
        if output_stream.write_from_stream == nil or sub_task.no_chunked_download then
            log.info("二进制没有分块合并函数不分块,或者下载失败过");
            once_download_size = zip_size
            retry_time = 1 -- 不分块失败了就直接没
        end
        local cur_download_size = last_download_size >= once_download_size and once_download_size or last_download_size
        last_download_size = last_download_size - cur_download_size
        output_stream_list[#output_stream_list + 1] = output_stream
        local download_range = ("bytes=%d-%d"):format(start_pos, start_pos + cur_download_size - 1)
        if zip_size > once_download_size then
            log.info(("分块下载 zip_size[%s] url[%s] Range[%s]"):format(tostring(zip_size), tostring(url), download_range))
        end
        start_pos = start_pos + cur_download_size
        local pro = base.as_promise(function()
            local end_pos = start_pos
            return table.pack(
                self:request_http_download_zip_block(url, sub_task, download_range, end_pos, output_stream, retry_time)
            )
        end)
        table_insert(down_load_finish_promise_list, pro)
    end

    local final_code = 0
    local final_status = 200
    local final_stream
    final_stream = output_stream_list[1]
    for i = 1, #down_load_finish_promise_list do
        local code, status = table.unpack(down_load_finish_promise_list[i]:co_result())
        if code == 0 and (status == 200 or status == 206) then
            if i > 1 then
                final_stream:write_from_stream(output_stream_list[i])
                output_stream_list[i]:clear()
            end
        else
            final_code, final_status = code, status
        end
    end
    if final_code == 0 and (final_status == 200 or final_status == 206) then
        self.save_file_buffer[full_path] = final_stream
    else
        for i = 1, #output_stream_list do --下载失败全部清空
            output_stream_list[i]:clear()
        end
    end

    if io_exist_file(full_path) then
        if not io_remove(full_path) then
            log.error("remove file failed", full_path)
            return -1, 0
        end
    end

    return final_code, final_status
end

---@param sub_task UpdateSubTask
---@param use_patch boolean
function UpdateTask:download_zip(sub_task, use_patch)
    local download_info = nil  ---@type update_info_row|PatchInfo
    if use_patch then
        download_info = sub_task.info.patch_info
    else
        download_info = sub_task.info
    end

    local full_path, full_path_parent = self:calc_download_filename(sub_task, download_info)
    io_create_dir(tostring(full_path_parent))
    local main_url = use_patch and sub_task.info.patch_info.url or sub_task.info.url
    local zip_size = use_patch and sub_task.info.patch_info.size or sub_task.info.size

    local download_url_list = {}
    if not (use_patch and main_url:find('alpha-maps-1257933509.cos.ap-shanghai.myqcloud.com', 1, true)) then
        for _, replace in ipairs(replace_url_list) do
            local new_url = replace(main_url)
            if new_url and new_url ~= main_url then
                table_insert(download_url_list, new_url)
                table_insert(download_url_list, new_url)  -- 插入两次, 给两次机会
            end
        end
    end
    -- 重试次数非0时，才插入原链接，即：若第一次尝试下载，只尝试cdn
    if not (sub_task.retry_times_on_error == 0) then
        local found = false
        for _, v in ipairs(download_url_list) do
            if v == main_url then
                found = true
            end
        end
        if not found then  -- 没有main_url, 就把main_url放最后一个
            table_insert(download_url_list, main_url)
        end
    end
    --table.unique(download_url_list)  -- 对于正常的非master环境, 最终应该只有一个url


    local err = nil
    local retry_times_on_timeout = 0
    local retry_times_on_error = sub_task.retry_times_on_error
    local max_retry_times_on_error = 5

    for i = 1, #download_url_list do
        local url = download_url_list[i]
        if type(url) ~= 'string' then
            log.error(fmt("url: %s, type: %s, main_url: %s", url, type(url), main_url))
            assert(false)
        end
        local http = nil
        try {
            function()
                log.info(('download[%s] begin'):format(url))

                local downloaded_bytes = 0
                if io_exist_file(full_path) then
                    local err_code, file_size = io_file_size(full_path)
                    if err_code ~= 0 then
                        io_remove(full_path)
                        error(('神马贵啊, full_path[%s] file_size获取不到!!!'):format(full_path))
                    end

                    if zip_size >= file_size then
                        downloaded_bytes = file_size
                        log.info(fmt("[%s]使用Range(%s-)下载", url, downloaded_bytes))
                    else
                        if zip_size == 0 then
                            -- server版本的zip在数据库没有存size, 所以只能每次重下了...
                            downloaded_bytes = 0
                            log.warn(fmt("package[%s] remote_zip_size == 0, 只能每次重下", sub_task.info.name))
                        else  --
                            downloaded_bytes = 0
                            log.warn(fmt('url[%s] remote_zip_size[%s] < file_size[%s], 只好重下', url, zip_size, file_size))
                        end

                        io_remove(full_path)
                    end
                end
                if sub_task.download_file_to_mem then
                    downloaded_bytes = 0
                end
                assert(zip_size == 0 or zip_size >= downloaded_bytes)
                if zip_size ~= downloaded_bytes or zip_size == 0 then
                    local code,status
                    if sub_task.download_file_to_mem then
                        code, status = self:request_http_download_zip_to_mem(url, zip_size, sub_task, full_path, downloaded_bytes)
                    else
                        code, status = self:request_http_download_zip_to_file(url, zip_size, sub_task, full_path, downloaded_bytes)
                    end
                    if code == 0 and (status == 200 or status == 206) then  -- 206时断点续传的成功码
                        sub_task.info.true_url = url -- 记录下载使用的url
                        log.info(("download[%s] finish"):format(sub_task.info.name))
                        err = nil
                    elseif code == 28 then  -- CURLE_OPERATION_TIMEDOUT
                        -- 可能是速度太慢了, 要重试...
                        -- 不需要加retry_times_on_error, 反正不更新完也不能玩游戏, 超时就超时, 玩家如果忍不住, 自己就会杀进程了
                        retry_times_on_timeout = retry_times_on_timeout + 1
                        --if argv.has('download_abort_stat') then
                            common.stat_sender('download_abort', {
                                url = url,
                                downloaded = sub_task.max_downloaded,
                                reason = 1,
                                code = code,
                                policy_id = self.policy.policy_id,
                                thread_count = self.policy.thread_count,
                                retry_times_on_timeout = retry_times_on_timeout,
                                retry_times_on_error = retry_times_on_error,
                                platform = current_platform,
                            })
                        --end
                        throw(fmt("download zip[%s] to path[%s] timeout, retry it!", url, full_path))
                    elseif status == 404 or status == 403 then
                        common.stat_sender('download_abort', {
                            url = url,
                            downloaded = sub_task.max_downloaded,
                            reason = 3,
                            code = code,
                            policy_id = self.policy.policy_id,
                            thread_count = self.policy.thread_count,
                            retry_times_on_timeout = retry_times_on_timeout,
                            retry_times_on_error = retry_times_on_error,
                            platform = current_platform,
                        })
                        io_remove(full_path)
                        throw(fmt("request url[%s] failed, status[%d]", url, status))
                    else
                        -- 这时不应该删文件, 因为我们有断点续传
                        --if argv.has('download_abort_stat') then
                            common.stat_sender('download_abort', {
                                url = url,
                                downloaded = sub_task.max_downloaded,
                                reason = 2,
                                code = code,
                                policy_id = self.policy.policy_id,
                                thread_count = self.policy.thread_count,
                                retry_times_on_timeout = retry_times_on_timeout,
                                retry_times_on_error = retry_times_on_error,  -- retry_times_on_error一旦出现, max_downloaded就可能不准了
                                platform = current_platform,
                            })
                        --end
                        throw(fmt('download zip[%s] to path[%s] failed, code[%s], status[%s]', url, full_path, code, status))
                    end
                else
                    self:_try_set_max_download(sub_task, downloaded_bytes)
                    log.info(fmt("package[%s] 已被下完, 坐等MD5验证", sub_task.info.name))
                    err = nil
                end

                if not err then
                    if self:check_md5(full_path, use_patch and sub_task.info.patch_info.md5 or sub_task.info.md5, url, sub_task) then
                        err = nil
                        return  -- 成功了
                    else
                        common.stat_sender('download_abort', {
                            url = url,
                            downloaded = sub_task.max_downloaded,
                            reason = 7,
                            code = 0,
                            policy_id = self.policy.policy_id,
                            thread_count = self.policy.thread_count,
                            retry_times_on_timeout = retry_times_on_timeout,
                            retry_times_on_error = retry_times_on_error,  -- retry_times_on_error一旦出现, max_downloaded就可能不准了
                            platform = current_platform,
                        })
                        io_remove(full_path)
                        throw(fmt('check md5 failed. url[%s]', url))
                    end
                else
                    throw(err)
                end
            end,
            catch = function(e)
                log.warn(('download[%s] failed, reason:%s, retry_times_on_error: %s'):format(url, e, sub_task.retry_times_on_error))
                err = to_exception(e)
            end,
            finally = function()
                if http then
                    self.running_http_hub[http] = nil
                end
            end
        }

        if not err then
            return full_path
        end
    end
    
    retry_times_on_error = retry_times_on_error + 1
    coroutine.sleep(3000)

    if retry_times_on_error < max_retry_times_on_error then
        sub_task.retry_times_on_error = retry_times_on_error
        return "download_failed"
    else
        error(err)
    end
end

---@param sub_task UpdateSubTask
function UpdateTask:download_thread_run_one(sub_task)
    local use_patch = false
    sub_task.use_patch = false--这里加了个标记，因为应用补丁移到了解压线程里
    if not sub_task.patch_failed and sub_task.info.patch_info then
        -- 尝试走patch
        use_patch = true
        sub_task.use_patch = true
    end

    local zip_path = self:download_zip(sub_task, use_patch)
    
    if zip_path == "download_failed" then
        return "download_failed"
    end

    sub_task.zip_path = zip_path

    if not self.to_unzip_deque:closed() then
        if sub_task.download_file_to_mem then --下载到内存里的先解压
            self.to_unzip_deque:push_front(sub_task)
        else
            self.to_unzip_deque:push_back(sub_task)
        end
    else
        log.info(('download[%s] success, but to_unzip_deque closed, so ignore it'):format(sub_task))
    end
end

function UpdateTask:download_thread_run(i)
    try {
        function()
            log.info(("task: %s, download_thread_run[%s] begin"):format(self, i))
            while true do
                if self.to_download_deque:closed() then
                    log.info(('to_download_deque has closed, exit download_thread_run[%s]'):format(i))
                    return
                end
                local sub_task, err = self.to_download_deque:co_pop_front()   ---@type UpdateSubTask
                log.info(('download_thread_run got sub_task[%s]'):format(sub_task))
                if not sub_task then
                    assert(err == 'closed')
                    return
                end

                if self.status ~= 'pending' then
                    log.info(("task: %s, download_thread_run[%s] exit, because status[%s]"):format(self, i, self.status))
                    return
                end

                local zip_orgin_size = sub_task.info.original_size or sub_task.info.size --使用原大小
                local use_mem_buffer = ((self.used_memory + zip_orgin_size < self.max_can_use_mem) and
                    self.download_used_mem < self.max_download_can_used_mem --下载再加个限制
                    and do_unzip_from_mem ~= nil)
                if  sub_task.info.url then
                    local dot_split_result = split(sub_task.info.url, '.')
                    local ext = dot_split_result[#dot_split_result]
                    if ext == "zip" then
                        use_mem_buffer = false -- zip暂时不能用内存解压
                    end
                end
                if sub_task.download_file_to_mem == nil or sub_task.download_file_to_mem == true then 
                    sub_task.download_file_to_mem = use_mem_buffer -- 如果之前下载到文件 不能改成下载到内存 不然文件下载到一半下载失败会浪费 
                end
                if use_mem_buffer then
                    self.used_memory = self.used_memory + zip_orgin_size
                    self.download_used_mem = self.download_used_mem + zip_orgin_size
                    log.info(("下载到内存 name[%s]"):format(sub_task.info.alias or sub_task.info.name))
                    log.info(("剩余内存 [%d]MB [%d]KB"):format(self:get_last_memory()))
                    log.info(("下载已经使用的内存 [%d]MB [%d]KB"):format(self:format_memory(self.download_used_mem)))
                else
                    log.info(("下载到文件 name[%s]"):format(sub_task.info.alias or sub_task.info.name))
                end

                if self:download_thread_run_one(sub_task) == 'download_failed' then
                    if use_mem_buffer then
                        self.used_memory = self.used_memory - zip_orgin_size
                        self.download_used_mem = self.download_used_mem - zip_orgin_size
                        log.info(("下载已经使用的内存 [%d]MB [%d]KB"):format(self:format_memory(self.download_used_mem)))
                    end
                    log.warn(("download_failed! %s"):format(json.encode(sub_task)))
                    sub_task.no_chunked_download = true -- 下载失败后 不再分块下载
                    sub_task.download_file_to_mem = false -- 下载失败后 不再下载到内存
                    self.to_download_deque:push_front(sub_task)
                end
            end
        end,
        catch = function(e)
            log.error(("task: %s, download_thread_run[%s] abort, err[%s]"):format(self, i, e))
            self:abort()
        end
    }

    self.remain_thread_count = self.remain_thread_count - 1
end

function UpdateTask:get_last_memory()
    local mb = math_floor((self.max_can_use_mem - self.used_memory) / 1024 / 1024)
    local kb = math_floor((self.max_can_use_mem - self.used_memory) / 1024)
    return mb, kb, (self.max_can_use_mem - self.used_memory)
end

function UpdateTask:format_memory(value)
    local mb = math_floor(value / 1024 / 1024)
    local kb = math_floor(value / 1024)
    return mb, kb, value
end

function UpdateTask:unzip_thread_run()
    try {
        function()
            while true do
                if self.to_unzip_deque:closed() then
                    log.infof('to_unzip_deque has closed, exit unzip_thread_run')
                    return
                end
                local sub_task, err = self.to_unzip_deque:co_pop_front()
                log.info(('got unzip_thread_run run sub_task[%s]'):format(sub_task))
                if not sub_task then
                    assert(err == 'closed')
                    return
                end

                if self.status ~= 'pending' then
                    log.info(("task: %s, unzip_thread_run exit, because status[%s]"):format(self, self.status))
                    return
                end

                local zip_orgin_size = sub_task.info.original_size or sub_task.info.size --使用原大小
                -- 解压超内存 且当前已经有其他文件在解压 如果没有其他文件在解压，当前就算会超内存也要解压,不然可能卡主
                while self.used_memory + zip_orgin_size > self.max_can_use_mem and self.unziping_thread > 0 do
                    log.info("解压超内存等一等")
                    sleep(1000)
                end
                self.unziping_thread = self.unziping_thread + 1
                self.used_memory = self.used_memory + zip_orgin_size -- 解压使用的空间大小,使用原大小
                log.info(("剩余内存 [%d]MB [%d]KB"):format(self:get_last_memory()))

                if self:unzip_thread_run_one(sub_task) == 'new_patch_failed!' then--应用补丁移到了解压线程里，如果应用失败了，还要重新下完整包
                    log.error(("new_patch_failed! %s"):format(json.encode(sub_task)))
                    sub_task.patch_failed = true
                    self.to_download_deque:push_front(sub_task)
                else
                    self.finished_size = self.finished_size + (sub_task.info.original_size or sub_task.info.size)
                    self.finished_count = self.finished_count + 1
                end
                self.used_memory = self.used_memory - zip_orgin_size
                self.unziping_thread = self.unziping_thread - 1
                log.info(("解压结束还原内存 [%d]MB [%d]KB"):format(self:get_last_memory()))
                if self.finished_count >= self.all_count then
                    log.info("更新结束后内存状态",self:get_last_memory())
                    self.to_download_deque:close()
                    self.to_unzip_deque:close()
                    self:set_status('success')
                    log.info(("更新大成功[%s]"):format(self))
                    return
                end
            end
        end,
        catch = function(e)
            log.error(("task: %s, unzip_thread_run abort, err[%s]"):format(self, e))
            self:abort()
        end
    }
end

local function hack_delete_old_one_package_archive(map_cache_folder)
    -- 取出这个文件夹里所有文件名, 把文件名按照数字排序, 保留版本号最大的, 其他的删掉
    local suc, li = io_list(tostring(map_cache_folder), 1)
    if suc == 0 then
        local version_li = {}
        for _, file in ipairs(li) do
            file = path_last_part(file)
            local dot_index = file:find('.', 1, true)
            local base_name = file:sub(1, dot_index)
            local suffix = file:sub(dot_index + 1)
            -- 以前有bug, 导致suffix可能多一个".", 所以得多判几个可能
            if suffix == 'zip' or suffix == '7z' or suffix == '.zip' or suffix == '.7z' then
                --log.alert("dot_index", dot_index)
                local ver = tonumber(base_name)
                --log.alertf("ver: %s", ver)
                if ver ~= nil then
                    table.insert(version_li, {ver = ver, file = file})
                end
            end
        end
        table.sort(version_li, function(a, b) return a.ver < b.ver  end)
        if #version_li > 1 then
            table.remove(version_li)
            for _, v_t in ipairs(version_li) do
                local to_delete_file = tostring(path(map_cache_folder) / v_t.file)
                log.debug(fmt('hack_delete_old_package, delete expired archive: %s', to_delete_file))
                io_remove(to_delete_file)
            end
        end
    end
end

---@param sub_task UpdateSubTask
function UpdateTask:unzip_thread_run_one(sub_task)
    local package_name = sub_task.info.name

    local final_folder_name = sub_task.info.alias or package_name  -- 如果有alias则使用alias, 否则默认package_name

    local package_res_path = fmt('%s/%s', sub_task.info.path, final_folder_name)
    local extract_folder = package_res_path ..'-'..sub_task.info.version .. '_new'

    --log.info(('unzip[%s] begin old_path[%s] extract_path[%s]'):format(package_name, old_path, extract_path))

    -- if sub_task.info.is_server and package_res_path:sub(1, 4) == 'Res/' then
    --     package_res_path = "HostRes/"..package_res_path:sub(4)
    --     extract_folder = "HostRes/".. extract_folder:sub(4)
    -- end

    local old_package_path = tostring(self.update_folder_root / package_res_path)
    extract_folder = tostring(self.update_folder_root / extract_folder)
    local is_new_patch = 0--是否为新的7z补丁包

    log.info(fmt("old_package_path[%s] extract_folder[%s]", old_package_path, extract_folder))

    if sub_task.use_patch then--这里是把原来在download线程里的应用补丁移过来了
        -- 多API的情况 LunkIke
        -- 把旧版本的文件完全复制一份到新版本的路径下 再打补丁
        api_pak_version_manager:load()
        if api_pak_version_manager:is_multi_api(sub_task.info.name) then --
            local old_info_version_path       = tostring(self.update_folder_root / package_res_path:gsub(sub_task.info.patch_info.dest .. '/' .. final_folder_name, tostring(sub_task.info.patch_info.src) .. '/' .. final_folder_name))
            local no_version_package_res_path = fmt('%s/%s', sub_task.info.origin_path, final_folder_name)
            local old_info_no_version_path    = tostring(self.update_folder_root / no_version_package_res_path)
            old_info_no_version_path = string.gsub(old_info_no_version_path, '//', '/')--去除可能得双斜杠
            if io_exist_dir(old_info_version_path) then
                if not io_copy_to_folder(old_info_version_path, old_package_path, false, true) then
                    log.info(('多API包应用补丁失败 旧文件复制失败 旧路径[%s]新路径[%s]'):format(old_info_version_path, old_package_path))
                    return 'new_patch_failed!'
                else
                    log.info(('多API包 复制成功 旧路径[%s]新路径[%s]'):format(old_info_version_path, old_package_path))
                end
            elseif io_exist_dir(old_info_no_version_path) then
                if not io_copy_to_folder(old_info_no_version_path, old_package_path, false, true) then
                    log.info(('多API包应用补丁失败 旧文件复制失败 旧路径[%s]新路径[%s]'):format(old_info_no_version_path, old_package_path))
                    return 'new_patch_failed!'
                else
                    log.info(('多API包 复制成功  旧路径[%s]新路径[%s]'):format(old_info_no_version_path, old_package_path))
                end
            else
                log.info(('多API包应用补丁失败 找不到旧文件路径 路径1[%s] 路径2[%s]'):format(old_info_version_path, old_info_no_version_path))
                return 'new_patch_failed!'
            end
        end
        
        -- 合并patch
        local result = self:merge_patch(sub_task, sub_task.zip_path, old_package_path, extract_folder)
        --result如果为空则应用补丁失败，返回走下载完整包流程
        if not result then
            log.info('new patch failed!')
            return 'new_patch_failed!'
        end
        is_new_patch = 1 -- 只有新补丁
        log.info("patch应用完了")
    end
    if is_new_patch == 0 then --如果不是新的7z补丁包，才走解压删除和替换
        local _,filesize 
        if not sub_task.download_file_to_mem then
            _, filesize = io_file_size(sub_task.zip_path)
        else
            filesize= self.save_file_buffer[sub_task.zip_path]:get_size()
        end
        log.info("压缩包大小:"..filesize)
        log.info(('解压路径 : %s'):format(extract_folder))
        log.info(('准备解压 : %s ...'):format(sub_task.zip_path))

        if io_exist_dir(extract_folder) then
            --sleep(100)
            log.warn(('extract_path[%s]已存在, 先把它删了'):format(extract_folder))
            if io_remove(extract_folder) ~= 0 then
                throw(fmt('删除extract_path[%s]失败', extract_folder))
            end
        end

        -- 注意这里是多线程
        local has_add_extracted = 0 -- 已经计算的提取的字节数

        local result = -1
        if not sub_task.download_file_to_mem then
            result = do_unzip(sub_task.zip_path, extract_folder, function(total, progress, path)
                self.extracted_bytes = self.extracted_bytes + (progress - has_add_extracted)   -- 修正总共提取的字节数
                has_add_extracted = progress
                self.update_progress()
            end)
        else
            if self.save_file_buffer[sub_task.zip_path] then
                result = do_unzip_from_mem(self.save_file_buffer[sub_task.zip_path], extract_folder, function(total, progress, path)
                    self.extracted_bytes = self.extracted_bytes + (progress - has_add_extracted)   -- 修正总共提取的字节数
                    has_add_extracted = progress
                    self.update_progress()
                end)
            else
                log.info("找不到解压文件 和 http流")
            end
        end
        self.extracted_bytes = self.extracted_bytes + ((sub_task.info.original_size or sub_task.info.size)  - has_add_extracted)-- 提取结束后 增加量 一定是初始大小
        self.update_progress()
        if self.save_file_buffer[sub_task.zip_path] then
            self.save_file_buffer[sub_task.zip_path]:clear();
            self.save_file_buffer[sub_task.zip_path] = nil -- 释放内存里的文件
            local zip_orgin_size = sub_task.info.original_size or sub_task.info.size --使用原大小
            self.used_memory = self.used_memory - zip_orgin_size -- 解压结束 释放下载到内存的文件流
            self.download_used_mem  = self.download_used_mem - zip_orgin_size
            log.info(("从内存解压结束还原下载内存 [%d]MB [%d]KB"):format(self:get_last_memory()))
            log.info(("下载已经使用的内存 [%d]MB [%d]KB"):format(self:format_memory(self.download_used_mem)))
        end

        if result ~= 0 then
            if __lua_state_name == 'StateEditor' then
                local EMessageBox = ImportSCEContext():GetEMessageBox()
                EMessageBox:begin(fmt('解压资源到[%s]失败，错误码[%d]。', extract_folder, result))
            end
            throw(fmt('解压失败 %s ，错误码 %d', sub_task.zip_path, result))
        else
            if io_exist_file(sub_task.zip_path) then -- 可能是存在内存里的 要先判断有没有这个文件
                local remove_result = io_remove(sub_task.zip_path)
                if remove_result ~= 0 then
                    throw(fmt('删除cache[%s]失败', sub_task.zip_path))
                end
            end
        end

        log.info(('解压成功: %s'):format(extract_folder))
        local extract_path = extract_folder
        if sub_task.info.packet_type == 1003 or sub_task.info.packet_type == 1011 then
            -- 单文件包
            local res, files = io_list(extract_folder, 1)
            if res == 0 then
                local _, file_name = next(files)
                if file_name then
                    local ext = getextension(file_name)
                    if ext and #ext > 0 then
                        old_package_path = old_package_path..'.'..ext
                        extract_path = file_name
                        log.info("old_package_path[%s], extract_path[%s]", old_package_path, extract_path)
                    else
                        throw(fmt("单包解压文件没有后缀名. 已知files: %s", json.encode(files)))
                    end
                else
                    throw(fmt("找不到单包解压文件. 已知files: %s", json.encode(files)))
                end
            else
                throw(fmt("io_list('%s') failed.", extract_folder))
            end
        end

        --local res, dir_list = io_list(extract_path, 3)
        --if res == 0 then
        --    for i in pairs(dir_list) do
        --        log.info(dir_list[i])
        --    end
        --end
        if not (platform.is_wx() or platform.is_qq()) then
            local retry_count = 5
            while retry_count > 0 do
                if not io_exist_dir(old_package_path) and not io_exist_file(old_package_path)  then
                    break
                end

                if io_remove(old_package_path) == 0 then
                    log.info(('删除老路径: %s 成功'):format(old_package_path))
                    break
                end

                log.warn(('删除老路径: %s 失败'):format(old_package_path))
                retry_count = retry_count - 1
                sleep(100)
            end

            if retry_count == 0 then
                throw(fmt('删除老路径: %s 失败, 重试次数用完', old_package_path))
            end
        end

        --sleep_one_frame()

        log.info(('替换目录 %s -> %s'):format(extract_path, old_package_path))

        if not io_exist_dir(extract_path) and not io_exist_file(extract_path) then
            log.info('空包, 临时创建一个空文件夹替代')
            io_create_dir(extract_path)
        end

        local retry_count = 5
        local rename_flag = true
        if sub_task.info.packet_type == 1003 or sub_task.info.packet_type == 1011 then
            rename_flag = false
        end
        while retry_count > 0 and io_rename(extract_path, old_package_path, rename_flag) == false do
            log.warn('替换目录失败，稍后重试 ... ')
            sleep_one_frame()
            sleep(1000)
            retry_count = retry_count - 1
        end

        if retry_count == 0 then
            throw(fmt('替换目录 %s -> %s 失败', extract_path, old_package_path))
        end

        if sub_task.info.rename_pak then
            --重命名pak
            local res, files = io_list(old_package_path, 1)
            if res == 0 then
                local _, file_name = next(files)
                if file_name then
                    local ext = getextension(file_name)
                    if ext == 'pak' then
                        local pak_folder = path_parent(file_name)
                        local rename_file_name = pak_folder .. '/' .. sub_task.info.rename_pak .. '.' .. ext
                        if io_rename(file_name, rename_file_name, false) then
                            log.info('重命名pak成功：', rename_file_name)
                        end
                    end
                end
            end
        end
    end

    if sub_task.info.packet_type == 1003 or sub_task.info.packet_type == 1011 then
        if io_exist_dir(extract_folder) then
            io_remove(extract_folder)
        end
    end

    local_version:update_json(sub_task.info)
    local_version:save_cache(sub_task.info)
    update_recode:write(sub_task)

    log.info(('解压 %s 成功'):format(sub_task.zip_path))

    local zip_folder = path_parent(sub_task.zip_path)
    if io_exist_dir(zip_folder) then
        --log.alertf("zip_folder: %s", zip_folder)
        hack_delete_old_one_package_archive(zip_folder)
    end
end

---@param sub_task UpdateSubTask
function UpdateTask:_try_set_max_download(sub_task, new_size, end_pos)
    --log.info(fmt('sub_task: %s, new_size: %s, max_downloaded: %s', sub_task.info.name, new_size, sub_task.max_downloaded))
    if end_pos ~= nil then
        sub_task.downloaded_list[tostring(end_pos)] = new_size
        local total_size = 0
        for _, value in pairs(sub_task.downloaded_list) do
            total_size = total_size + value
        end
        new_size = total_size
    end

    if sub_task.max_downloaded <= new_size then
        if sub_task.max_downloaded < new_size and self.update_progress ~= nil then
            self.update_progress()
        end
        -- 总之就是取最大值
        -- 如果出现重下(比如md5校验失败, 或patch merge失败), 那么也不会重置这个数, 所以因为重下而多用了的流量没有在UI上体现
        self.downloaded_count = self.downloaded_count + (new_size - sub_task.max_downloaded)
        sub_task.max_downloaded = new_size
    end
end

---@param sub_tasks UpdateSubTask[]
function UpdateTask:_search_undone_packages(sub_tasks)
    for i = 1, #sub_tasks do
        if self.status ~= 'pending' then
            return
        end
        local sub_task = sub_tasks[i]
        local info = sub_task.info
        if not info.patch_failed and info.patch_info then
            info = info.patch_info
        end

        local full_path = self:calc_download_filename(sub_task, info)
        if io_exist_file(full_path) then

            local code, downloaded = io_file_size(full_path)
            if code == 0 then
                log.info(fmt("io_exist_file(%s) true, size: %s", full_path, downloaded))
                self:_try_set_max_download(sub_task, downloaded)
            else
                local str = fmt("io_exist_file(%s) return true, but io_file_size return code: %s", full_path, code)
                throw(str)
            end

        end

        if i % 10 == 0 then
            sleep_one_frame()
        end
    end

    log.info(fmt('_search_undone_packages finish'))
end

function UpdateTask:get_max_can_use_mem()
    if __lua_state_name == 'StateEditor' then
        return 2000 * 1024 * 1024 -- 编辑器多用一点
    end
    if platform.is_win() then
        return 1000 * 1024 * 1024 -- Windows 多用一点
    elseif platform.is_android() then
        return 1000 * 1024 * 1024 -- 安卓多一点
    elseif platform.is_ios() then
        return 500 * 1024 * 1024
    end
    return 300 * 1024 * 1024      -- 最多使用300M
end

-- 下载用的内存 为总内存一半 
function UpdateTask:get_max_download_can_use_mem()
    -- 测试md5debug模式下 只能用文件下载
    if argv.has('md5_failed_debug') then
        return 0
    end
    if __lua_state_name == 'StateEditor' then
        return 1000 * 1024 * 1024 -- 编辑器多用一点
    end
    if platform.is_win() then
        return 500 * 1024 * 1024 -- Windows 多用一点
    elseif platform.is_android() then
        return 500 * 1024 * 1024 -- 安卓多一点
    elseif platform.is_ios() then
        return 250 * 1024 * 1024
    end
    return 150 * 1024 * 1024      -- 最多使用300Ms
end

function UpdateTask:_run()
    log.info(fmt("更新开始, task: %s, total_download_size: %s", self, self.total_download_size))
    log.info(("需更新: %s"):format(json.encode(self.to_download_list)))
    self.policy = calc_low_speed_policy()

    local sub_tasks = {}

    for _, row in ipairs(self.to_download_list) do
        local sub_task = setmetatable({
            info = row, max_downloaded = 0,
            downloaded_list = {},
            retry_times_on_error = 0,
        }, UpdaterSubTask)
        self.to_download_deque:push_back(sub_task)
        table_insert(sub_tasks, sub_task)
        self.all_size = self.all_size + (row.original_size or row.size)
    end

    self.all_count = #self.to_download_deque
    log.info(("task[%s] all need download count[%s]"):format(self, self.all_count))
    assert(self.all_count > 0)

    self.thread_count = min(self.all_count, max_thread_count)
    self.remain_thread_count = self.thread_count

    if not self.request.progress_bind then
        self.request.progress_bind =  DefaultProgressBind.new()
        --重写下show
        function self.request.progress_bind:show(show, reason, startup)
            if show then
                log.info('progress_show show, reason:'..reason)
                if startup then
                    self.bind.loading_icon_show = false
                else
                    self.bind.loading_icon_show = true
                end
                self.bind.status = '正在更新'
                self.bind.progress = 0
            else
                log.info('progress_show hide, reason:'..reason)
            end
            self.bind.show = show
        end
    end

    local old_set_status = self.request.progress_bind.set_status  -- 劫持原本set_status, 加入打点数据
    local self_task = self
    self.last_update_progress_bstat_time = common.utc_time()
    self.download_end = false
    function self.request.progress_bind:set_status(params)
        --self._now_downloaded = params.now_downloaded or self._now_downloaded
        --self._total_size = params.total_size or self._total_size
        --self._now_speed = params.now_speed or self._now_speed
        --self._installed_count = params.installed_count or self._installed_count
        --self._to_install_count = params.to_install_count or self._to_install_count

        -- if params.now_downloaded and self._now_downloaded ~= params.now_downloaded then
        --     --log.debug(("reason[%s], progress_bind._now_downloaded[%s], params.now_downloaded[%s]"):format(self_task.request.reason, self._now_downloaded, params.now_downloaded))
        -- end

        -- if params.installed_count and self._installed_count ~= params.installed_count then
        --     --log.debug(("reason[%s], progress_bind._installed_count[%s], params.installed_count[%s]"):format(self_task.request.reason, self._installed_count, params.installed_count))
        -- end
        local cur_time = common.utc_time()
        if cur_time - self_task.last_update_progress_bstat_time > 9000 then
            self_task.last_update_progress_bstat_time = cur_time
            common_stat_sender('update_progress_bstat', {
                guest_id = account.get_guest_id(),
                reason = self_task.request.reason,
                session_id = self_task.request.session_id,
                now_downloaded = params.now_downloaded,
                total_size = params.total_size,
                installed_count = params.installed_count,
                to_install_count = params.to_install_count,
                policy_id = self_task.policy_id,
                thread_count = self_task.thread_count,
                platform = current_platform,
            })
        end
        old_set_status(self, params)
    end

    self.request.progress_bind:reset()
    if self.startup then
        self.request.progress_bind:show(true, 'normal update', true)
    else
        self.request.progress_bind:show(true, 'normal update')
    end
    self.request.progress_bind:display()

    log.info(fmt('download thread count: %s', self.thread_count))

    coroutine_async(function()
        self:_search_undone_packages(sub_tasks)
    end)

    self.max_can_use_mem = self:get_max_can_use_mem()
    self.max_download_can_used_mem = self:get_max_download_can_use_mem()

    self.max_download_speed = 0 -- 最大下载速度
    self.download_used_mem = 0          -- 下载使用的内存
    self.unzip_used_mem = 0             -- 解压使用的内存
    self.used_memory = 0                 -- 已经使用的内存
    self.save_file_buffer = {}           --暂存下载的文件流
    self.unziping_thread = 0             -- 正在解压的文件数
    self.max_http_request = 30           -- 最多请求的http数
    self.used_http_request = 0           -- 已经使用的http请求
    self.downloaded_data = {}       -- 储存之前下载的时间区间 和 下载量
    self.standard_deviation = 0     -- 下载速度标准差

    for i = 1, self.thread_count do  -- 开多个协程来并行下载
        table.insert(self.download_thread_finish_promise_list, base.as_promise(self.download_thread_run, self, i))
    end

    local unzip_thread_number = 1
    if type(io.unzip_file_from_mem) == "function" then --存在从内存解压就存在多线程解压
        unzip_thread_number = 7  -- 线程数上限由C++里决定 这些同时解压的数量还收到内存限制
    else
        self.max_can_use_mem = 0 -- 说明二进制没有下载到内存 只能按照旧方法下载到内存和解压
    end
    for _ = 1, unzip_thread_number do
        table.insert(self.unzip_thread_finish_promise_list, base.as_promise(self.unzip_thread_run, self))
    end

    self.latest_downloaded = 0.0
    self.latest_update_time = common.utc_time()
    self.update_end = false
    self.update_progress = function()
        local diff = self.downloaded_count - self.latest_downloaded
        local cur_time = common.utc_time()
        local delay = cur_time - self.latest_update_time
        delay = max(delay, 1)
        local downloading = not self.download_end
        if self.downloaded_count == self.total_download_size and self.download_end == false then
            self.download_end = true                 -- 第一次下载完所有文件 刷新一次
            self.last_update_progress_bstat_time = 0 -- 下载结束发送一次更新信息
        else
            if not self.update_end and delay < 230 then
                return
            end
        end
        if self.update_end then
            self.last_update_progress_bstat_time = 0 -- 更新结束发送一次更新信息
        end
        self.latest_update_time = cur_time
        self.latest_downloaded = self.downloaded_count
        if downloading then
            self.downloaded_data[#self.downloaded_data + 1] = { time = delay, byte = diff * 1000 /1024 }
            if self.download_end then --下载结束
                local download_time = 0
                local tot_download = 0
                for _, data in ipairs(self.downloaded_data) do
                    download_time = download_time + data.time
                    tot_download = tot_download + data.byte
                end
                local uspeed = self.downloaded_count * 1000 / 1024 / download_time -- 平均速度 KB/s
                local sd = 0
                for _, data in ipairs(self.downloaded_data) do
                    local cspeed = data.byte / data.time
                    local add = (cspeed - uspeed) * (cspeed - uspeed) * data.time / download_time
                    sd = sd + add
                end
                self.standard_deviation = math_sqrt(sd)
                log.info("平均速度", uspeed)
                log.info("更新速度标准差", self.standard_deviation)
            end
        end

        log.info("UI更新请求间隔", delay)
        local speed = diff * 1000 / delay
        if speed < 0 then
            speed = 0
        end
        self.max_download_speed = max(self.max_download_speed, math_floor(speed))
        self.request.progress_bind:set_status {
            now_downloaded = self.downloaded_count,
            total_size = self.total_download_size,
            now_speed = speed,
            installed_count = self.finished_count,
            to_install_count = self.all_count,
            to_install_size = self.all_size,
            installed_size = self.finished_size,
            progress_bytes = 1 * self.downloaded_count + self.extracted_bytes / 3.0,
            total_bytes = 1 * self.total_download_size + self.to_extract_bytes / 3.0,
        }
    end

    local timer3_handle = nil
    if argv.has('test_download_reconnect') then
        timer3_handle = base.loop(6000, function()
            for http in pairs(self.running_http_hub) do
                log.info(fmt('call http close'))
                http:close()
            end
        end)
    end

    for i = 1, #self.download_thread_finish_promise_list do
        self.download_thread_finish_promise_list[i]:co_get()  -- 不看结果, 只要结束了就行了
    end

    for i = 1, #self.unzip_thread_finish_promise_list do
        self.unzip_thread_finish_promise_list[i]:co_get()  -- 不看结果, 只要结束了就行了
    end

    local_version:save()
    local_version:clear_cache()
    local_version:clear_patch_cache()
    api_pak_version_manager:save()
    map_pak_version_manager:save()
    self.save_file_buffer = {} -- 置为空表
    self.update_end = true
    self.update_progress() -- 更新结束时 再更新一次进度条
    if argv.has('test_download_reconnect') then
        timer3_handle:remove()
    end

    self.request.progress_bind:set_status {
        installed_count = self.finished_count,
        to_install_count = self.all_count,
        to_install_size = self.size,
        installed_size = self.finished_size
    }

    coroutine.sleep_one_frame()
    coroutine.sleep_one_frame()

    if (_G.IP:find('master') and self.status == 'success' and self.request.progress_bind ~= nil and self.request.progress_bind._to_install_count ~= nil and self.request.progress_bind._to_install_count > 0 and
            (self.request.progress_bind._installed_count == nil or self.request.progress_bind._installed_count == 0 )
        ) then
        log.error("更新错误,发送消息 已经安装的包数量过少", base.json.encode(self.request.progress_bind));
    end

    if self.status == 'success' then
        self.request.progress_bind:show(false, '正常hide')
    else
        self.request.progress_bind:show(false, '更新出错')
    end
end

function UpdateTask:run()
    try{
        function()
            if self.status ~= 'waiting' then
                log.info(('UpdateTask status[%s] ~= waiting, it finished!'):format(self))
                return
            end

            if #self.to_download_list == 0 then
                self:set_status('success')
                log.infof('to_download_list empty, 更新结束')
                return
            end

            self:set_status('pending')
            self:_run()
        end,
        catch = function(e)
            log.error(e)
            self:abort()
        end
    }
end

return UpdateTask
